# JollyAgent 数据流转与监控系统 PRD

## 1. 概述

### 1.1 背景

JollyAgent 是一个基于 ReAct 模式的 AI Agent 系统，目前缺乏完整的数据流转和可观测性能力。为了提升系统的可观测性、调试能力、数据分析能力和后续的模型优化，需要构建一个完整的数据流转管道，实现从数据收集、实时处理到持久化存储的全链路能力。

### 1.2 目标

构建一个完整的数据流转与监控系统，实现 JollyAgent 执行过程的全链路数据收集、实时处理、可视化监控和数据分析，支持数据导出用于标注系统，为后续的提示词和模型优化提供数据支撑。

### 1.3 问题陈述

- 缺乏对 Agent 执行过程的详细监控和实时分析
- 无法可视化查看执行流程和性能瓶颈
- 缺乏结构化的数据流转管道用于实时处理和分析
- 缺乏持久化的数据存储用于历史分析和机器学习
- 调试和问题排查困难
- 无法进行实时数据驱动的优化决策

## 2. 目标

### 2.1 主要目标

1. **全链路数据收集**: 实现用户查询到最终响应的完整执行链路数据收集
2. **实时数据流转**: 构建 Kafka -> Flink -> 数仓的实时数据处理管道
3. **可视化监控**: 提供直观的流程图和瀑布图展示执行过程
4. **数据分析能力**: 支持实时和离线数据分析，为业务决策提供支撑
5. **数据导出**: 支持结构化数据导出，便于标注系统使用
6. **性能分析**: 识别执行瓶颈，优化系统性能
7. **Docker 化部署**: 一键启动整个数据流转环境

### 2.2 成功指标

- 100% 的执行步骤被记录和追踪
- 数据流转延迟 < 5 秒
- 可视化界面响应时间 < 2 秒
- 数据导出格式标准化，支持 Excel 导入
- 系统性能影响 < 5%
- 数据丢失率 < 0.1%
- Docker 环境一键启动成功率 100%

## 3. 用户故事

### 3.1 开发者用户故事

- **作为开发者**，我希望能够实时查看 Agent 的执行流程，以便快速定位问题和优化性能
- **作为开发者**，我希望能够查看每个步骤的耗时，以便识别性能瓶颈
- **作为开发者**，我希望能够导出执行数据，以便进行模型优化和标注
- **作为开发者**，我希望能够通过 Docker 一键启动整个监控环境，以便快速搭建开发环境

### 3.2 运维用户故事

- **作为运维人员**，我希望能够监控系统的整体运行状态，以便及时发现异常
- **作为运维人员**，我希望能够查看历史执行记录，以便进行问题排查
- **作为运维人员**，我希望能够通过实时告警快速响应系统问题
- **作为运维人员**，我希望能够通过 Docker 容器化部署简化运维工作

### 3.3 产品经理用户故事

- **作为产品经理**，我希望能够分析用户查询模式，以便优化产品功能
- **作为产品经理**，我希望能够评估 Agent 的执行效果，以便制定改进计划
- **作为产品经理**，我希望能够基于实时数据做出产品决策
- **作为产品经理**，我希望能够分析用户行为趋势，以便制定产品策略

### 3.4 数据分析师用户故事

- **作为数据分析师**，我希望能够访问结构化的历史数据，以便进行深度分析
- **作为数据分析师**，我希望能够进行实时数据分析，以便发现业务洞察
- **作为数据分析师**，我希望能够基于数据构建预测模型，以便优化 Agent 性能

## 4. 功能需求

### 4.1 数据收集层

1. **OpenTelemetry 集成**

   - 集成 OpenTelemetry Python SDK
   - 配置 trace 和 span 收集
   - 实现自定义 instrumentation
   - 支持数据发送到 Kafka

2. **执行步骤追踪**

   - 用户输入接收追踪
   - Agent 思考过程（Think）追踪
   - 工具调用（Act）追踪
   - 工具执行结果（Observe）追踪
   - 最终响应生成追踪

3. **元数据收集**
   - 时间戳（开始时间、结束时间、耗时）
   - 输入/输出内容
   - 执行状态（成功/失败）
   - 错误信息和堆栈跟踪
   - 用户会话信息
   - 工具调用参数和结果
   - 性能指标（CPU、内存使用等）

### 4.2 数据流转层

1. **Kafka 消息队列**

   - 配置多个 Topic 用于不同类型的数据
   - 支持数据分区和负载均衡
   - 实现数据持久化和容错
   - 支持数据压缩和批量处理

2. **Flink 流处理**

   - 实时数据处理和转换
   - 数据清洗和验证
   - 实时统计和聚合
   - 异常检测和告警
   - 支持窗口计算和状态管理

3. **数据流转架构**
   ```
   JollyAgent -> OpenTelemetry -> Kafka -> Flink -> 数仓
        ↓              ↓           ↓        ↓        ↓
     业务数据      监控数据     消息队列   流处理    持久化存储
   ```

### 4.3 数据存储层

1. **数仓选择**

   - 实时分析：ClickHouse / Apache Druid
   - 历史数据：HDFS + Parquet
   - 结构化查询：PostgreSQL / MySQL
   - 向量存储：Milvus / Weaviate（用于相似性搜索）

2. **数据分层存储**

   - ODS 层：原始数据存储
   - DWD 层：清洗后的明细数据
   - DWS 层：汇总数据
   - ADS 层：应用数据

3. **数据格式规范**
   ```json
   {
     "session_id": "string",
     "conversation_id": "string",
     "user_id": "string",
     "timestamp": "ISO8601",
     "spans": [
       {
         "span_id": "string",
         "parent_span_id": "string",
         "name": "string",
         "start_time": "ISO8601",
         "end_time": "ISO8601",
         "duration_ms": "number",
         "attributes": {
           "step_type": "think|act|observe|response",
           "content": "string",
           "tool_name": "string",
           "status": "success|error",
           "error_message": "string"
         }
       }
     ]
   }
   ```

### 4.4 可视化层

1. **Grafana 集成**

   - 配置 Grafana 数据源
   - 创建自定义仪表板
   - 实现实时数据展示
   - 支持多数据源集成

2. **可视化组件**

   - 执行流程图（类似 Jaeger trace view）
   - 瀑布图（类似 Chrome DevTools）
   - 性能指标图表
   - 错误率统计图
   - 实时数据流图
   - 系统资源监控图

3. **交互功能**
   - 会话搜索和过滤
   - 时间范围选择
   - 执行步骤展开/折叠
   - 详细信息查看
   - 实时数据刷新

### 4.5 数据分析层

1. **实时分析**

   - 实时性能监控
   - 实时错误检测
   - 实时用户行为分析
   - 实时系统资源监控

2. **离线分析**

   - 历史数据趋势分析
   - 用户行为模式分析
   - 性能瓶颈分析
   - 业务指标分析

3. **机器学习支持**

   - 特征工程数据准备
   - 模型训练数据支持
   - 预测分析能力
   - 异常检测模型

### 4.6 数据导出层

1. **Excel 导出功能**

   - 支持按会话导出
   - 支持按时间范围导出
   - 支持自定义字段选择
   - 支持多工作表导出

2. **导出字段**

   - 用户查询内容
   - Agent 思考过程
   - 工具调用详情
   - 执行结果
   - 耗时统计
   - 错误信息
   - 性能指标

3. **数据格式**
   - 标准 Excel 格式（.xlsx）
   - 支持多工作表
   - 包含元数据说明
   - 支持数据透视表

### 4.7 Docker 化部署

1. **容器化组件**

   - Kafka 集群容器化
   - Flink 集群容器化
   - 数仓容器化（ClickHouse/PostgreSQL 等）
   - Grafana 容器化
   - 监控组件容器化

2. **编排管理**

   - Docker Compose 配置
   - 服务依赖管理
   - 网络配置
   - 数据卷管理
   - 环境变量配置

3. **一键启动**

   - 单命令启动整个环境
   - 自动健康检查
   - 服务状态监控
   - 日志统一管理

## 5. 非目标（Out of Scope）

1. **复杂告警系统**: 不包含复杂的告警规则和通知机制
2. **用户权限管理**: 不包含多用户权限控制
3. **数据加密**: 不包含敏感数据加密功能
4. **分布式追踪**: 不包含跨服务的分布式追踪
5. **实时流处理**: 不包含 Kafka -> Flink -> 标注系统的实时流处理
6. **复杂机器学习**: 不包含复杂的机器学习模型训练和部署

## 6. 设计考虑

### 6.1 架构设计

```
用户请求 -> JollyAgent -> OpenTelemetry SDK -> Kafka -> Flink -> 数仓
                                    ↓                    ↓        ↓
                              Grafana 可视化        实时分析    离线分析
                                    ↓                    ↓        ↓
                              数据导出 (Excel)      告警系统   机器学习
```

### 6.2 UI/UX 要求

- 简洁直观的界面设计
- 响应式布局，支持不同屏幕尺寸
- 快速加载和流畅交互
- 清晰的数据展示和导航
- 实时数据更新

### 6.3 性能要求

- 监控系统对主业务的影响 < 5%
- 数据流转延迟 < 5 秒
- 可视化界面响应时间 < 2 秒
- 支持至少 1000 个并发会话的监控
- 数据存储空间增长可控
- 支持 TB 级别的数据存储

## 7. 技术考虑

### 7.1 技术栈选择

- **监控框架**: OpenTelemetry Python SDK
- **消息队列**: Apache Kafka
- **流处理**: Apache Flink
- **数据存储**: ClickHouse / PostgreSQL / HDFS
- **可视化工具**: Grafana
- **数据导出**: pandas + openpyxl
- **容器化**: Docker + Docker Compose
- **Web 服务**: FastAPI（可选，用于 Grafana 数据源）

### 7.2 集成方式

- 使用 OpenTelemetry SDK 直接集成到 Agent 代码中
- 配置 OTLP exporter 输出到 Kafka
- 使用 Flink 进行实时数据处理
- 使用 Grafana 的多数据源插件
- 使用 Docker Compose 管理整个环境

### 7.3 依赖关系

- OpenTelemetry Python SDK
- Apache Kafka
- Apache Flink
- ClickHouse / PostgreSQL
- Grafana
- pandas
- openpyxl
- FastAPI（可选）
- Docker & Docker Compose

## 8. 成功指标

### 8.1 功能指标

- [ ] 100% 的执行步骤被正确记录
- [ ] 数据流转管道正常工作
- [ ] 可视化界面能够正确展示执行流程
- [ ] 数据导出功能正常工作
- [ ] 系统性能影响控制在 5% 以内
- [ ] Docker 环境一键启动成功

### 8.2 质量指标

- 监控数据准确性 99%+
- 数据流转延迟 < 5 秒
- 可视化界面响应时间 < 2 秒
- 数据导出成功率 100%
- 系统稳定性 99.9%
- 数据丢失率 < 0.1%

### 8.3 用户体验指标

- 开发者能够快速定位问题
- 运维人员能够有效监控系统
- 产品经理能够分析用户行为
- 数据分析师能够进行深度分析

## 9. 开放问题

1. **数据保留策略**: 监控数据需要保留多长时间？
2. **存储容量**: 预计每日产生的监控数据量？
3. **并发支持**: 系统需要支持的最大并发用户数？
4. **扩展性**: 未来是否需要支持分布式部署？
5. **安全性**: 是否需要考虑监控数据的安全保护？
6. **成本控制**: 如何控制数据存储和处理的成本？

## 10. 实施计划

### 10.1 第一阶段：基础数据收集

- 集成 OpenTelemetry SDK
- 实现基本的数据收集
- 配置本地文件存储（作为备份）
- 搭建 Docker 基础环境

### 10.2 第二阶段：数据流转管道

- 部署 Kafka 集群
- 配置数据发送到 Kafka
- 部署 Flink 集群
- 实现基础流处理逻辑

### 10.3 第三阶段：数据存储和可视化

- 部署数仓（ClickHouse/PostgreSQL）
- 集成 Grafana
- 创建基础仪表板
- 实现流程图展示

### 10.4 第四阶段：数据分析和导出

- 实现 Excel 导出功能
- 优化数据格式
- 完善元数据
- 实现实时分析功能

### 10.5 第五阶段：优化完善

- 性能优化
- 用户体验改进
- 文档完善
- Docker 环境优化

## 11. 风险评估

### 11.1 技术风险

- OpenTelemetry 集成复杂度
- Kafka 和 Flink 集群运维复杂度
- 性能影响控制
- 数据格式兼容性
- Docker 环境稳定性

### 11.2 项目风险

- 开发时间估算
- 依赖第三方工具
- 数据迁移需求
- 运维成本增加

### 11.3 缓解措施

- 充分的技术调研
- 渐进式实施
- 完善的测试计划
- 容器化简化部署
- 完善的监控和告警
